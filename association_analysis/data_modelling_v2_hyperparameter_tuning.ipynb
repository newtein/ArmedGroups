{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ast import literal_eval\n",
    "from numpy import nan\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from fancyimpute import KNN\n",
    "import missingno as msno\n",
    "from copy import deepcopy\n",
    "import impyute.imputation.cs.mice as mice_imputation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score, explained_variance_score, median_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_rows', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_actual, y_pred):\n",
    "    y_actual = y_actual['lifespan'].tolist()\n",
    "    y_pred = [i[0] if type(i) == list else i for i in y_pred.tolist()]\n",
    "    return (np.sum([np.abs((i-j)/i) for i,j in zip(y_actual, y_pred)])*100)/len(y_actual)\n",
    "\n",
    "def regression_report(y_true, y_pred):\n",
    "    ev = explained_variance_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "    except:\n",
    "        msle = \"error\"\n",
    "    medal = median_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape_score = mape(y_true, y_pred)\n",
    "    response = {\n",
    "        \"Explained Variance\": ev,\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"Mean Squared Log Error\": msle,\n",
    "        \"Median Absolute Error\": medal,\n",
    "        \"MAPE\": mape_score,\n",
    "        \"r2_score\": r2,\n",
    "        \"RMSE\": mse**0.5\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output/NAG_DETAILS_v8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = [\"nag_name\", \"ideology(s)\",'objective(s)']\n",
    "df.drop(delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/459 with 0 missing, elapsed time: 0.089\n",
      "Imputing row 101/459 with 0 missing, elapsed time: 0.091\n",
      "Imputing row 201/459 with 24 missing, elapsed time: 0.093\n",
      "Imputing row 301/459 with 0 missing, elapsed time: 0.097\n",
      "Imputing row 401/459 with 0 missing, elapsed time: 0.100\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['nagcode_1', 'lifespan'], axis=1)\n",
    "y = df[['lifespan']]\n",
    "# X_complete = mice_imputation(X.values)\n",
    "X_complete = KNN(k=4).fit_transform(X.values)\n",
    "\n",
    "X = pd.DataFrame(X_complete, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.0001, 0.005, 0.01, 0.025, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.5 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 7, 8, 10],\n",
    " \"min_child_weight\" : [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7 ],\n",
    " \"colsample_bytree\" : [ 0.1, 0.3, 0.4, 0.5 , 0.7, 0.8 ],\n",
    "  \"n_estimators\": [100, 150, 200, 250, 300, 350, 400],\n",
    "  \"sub_sample\": [1, 0.8]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_search=RandomizedSearchCV(regressor,param_distributions=params,\n",
    "                           n_iter=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs=6,\n",
    "                           cv=300,\n",
    "                           verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 300 folds for each of 5 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.23839664459229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 1500 out of 1500 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "random_search.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.2,\n",
       " 'learning_rate': 0.25,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 9,\n",
       " 'n_estimators': 100,\n",
       " 'sub_sample': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Explained Variance': 0.9888478627061943,\n",
       "  'MAPE': 23.517789303097484,\n",
       "  'Mean Absolute Error': 0.9458890024582761,\n",
       "  'Mean Squared Error': 1.6426317339661558,\n",
       "  'Mean Squared Log Error': 'error',\n",
       "  'Median Absolute Error': 0.7377566993236542,\n",
       "  'RMSE': 1.2816519550822507,\n",
       "  'r2_score': 0.9888478578820806},\n",
       " {'Explained Variance': 0.7599811656505073,\n",
       "  'MAPE': 86.34369262683049,\n",
       "  'Mean Absolute Error': 4.126031720443912,\n",
       "  'Mean Squared Error': 40.25715697158024,\n",
       "  'Mean Squared Log Error': 'error',\n",
       "  'Median Absolute Error': 2.964641571044922,\n",
       "  'RMSE': 6.344852793531166,\n",
       "  'r2_score': 0.7599702889575255})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(**{'colsample_bytree': 0.5,\n",
    " 'gamma': 0.2,\n",
    " 'learning_rate': 0.25,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 9,\n",
    " 'n_estimators': 100,\n",
    " 'sub_sample': 1})\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "Y_pred=model.predict(X_test)\n",
    "Y_pred_train=model.predict(X_train)\n",
    "\n",
    "regression_report(y_train, Y_pred_train),regression_report(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"output/weight.json\", \"rb\")\n",
    "weights = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.025,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 10,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_string(weight_dict, config_headers):\n",
    "    temp=[]\n",
    "    for i in config_headers:\n",
    "        temp.append(\"{}: {}\".format(i, weight_dict.get(i)))\n",
    "    return \",\\n\".join(temp)\n",
    "\n",
    "def make_report_string(weight_dict, config_headers, alias):\n",
    "    temp=[]\n",
    "    if 'sub_sample' not in weight_dict:\n",
    "        weight_dict.update({'sub_sample':1})\n",
    "    for i in config_headers:\n",
    "        temp.append(\"{}: {}\".format(alias.get(i,i), weight_dict.get(i)))\n",
    "    return \",\\n\".join(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model-III: Using Xgboost for regression.\n",
    "\n",
    "\n",
    "'''\n",
    "import csv\n",
    "fw = open(\"output/configurations.csv\", \"w\")\n",
    "writer = csv.writer(fw)\n",
    "headers = [\"Configuration Name\", \"Xgboost Hyperparameters\", \"Regression Report Training\", \"Regression Report Testing\"]\n",
    "config_headers = [\"max_depth\", \"colsample_bytree\", \"gamma\", \"n_estimators\", \"learning_rate\", \"min_child_weight\", \"sub_sample\"]\n",
    "report_headers = [\"Explained Variance\",\"Mean Squared Error\",\"Mean Absolute Error\",\"Median Absolute Error\",\"MAPE\",  \"r2_score\", \"RMSE\"]\n",
    "alias = {'RMSE': 'Root Mean Squared Error', 'MAPE': 'Mean Absolute Percentage Error', 'r2_score': 'R^2 Score'}\n",
    "writer.writerow(headers)\n",
    "for index, weight in enumerate(weights):\n",
    "    col1 = \"Configuration-{}\".format(index+1)\n",
    "    col2 = make_weight_string(weight, config_headers)\n",
    "    model = XGBRegressor(**weight)\n",
    "    model.fit(X_train, y_train) \n",
    "\n",
    "    Y_pred=model.predict(X_test)\n",
    "    Y_pred_train=model.predict(X_train)\n",
    "\n",
    "    train_report = regression_report(y_train, Y_pred_train)\n",
    "    test_report = regression_report(y_test, Y_pred)\n",
    "    col3 = make_report_string(train_report, report_headers, alias)\n",
    "    col4 = make_report_string(test_report, report_headers, alias)\n",
    "    writer.writerow([col1, col2, col3, col4])\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
